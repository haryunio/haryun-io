---
layout: post
title: "NVIDIA GTC 2025: Inspiration at the Frontier of AI"
categories: [articles]
tags: [Article, AI, Conference, NVIDIA, LLM]
featured_image_thumbnail: /images/GTC2025/GTC2025_main_pic.jpg
featured_image: /images/GTC2025/GTC2025_main_pic.jpg
featured: true
hidden: false
lang: en
page_id: nvidia-gtc-2025
---

I attended NVIDIA GTC 2025 in San Jose this March. I went there with a vague interest and curiosity, hoping to learn, but I returned with deep insights into where the industry was truly headed.


<!--more-->

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_main_pic.jpg" alt="NVIDIA GTC 2025 Main Venue" style="max-height: 400px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">The main venue at San Jose Convention Center.</figcaption>
</figure>

## First Impressions

GTC has a particular energy. Engineers, researchers, and founders (many of whom you've only interacted with through papers or GitHub) are suddenly standing next to you in line for coffee. The conversations happen fast and go deep.

This year's conference ran over 900 sessions covering generative AI, autonomous systems, robotics, and quantum computing. I couldn't attend everything I wanted to, but even the sessions I missed sparked useful hallway discussions with people who had.

## Jensen Huang's Keynote

The keynote is the main event. Jensen Huang has a way of presenting technical roadmaps that makes them feel inevitable—like you're not hearing predictions, but simply being told what's already in motion.

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_jensen_hwang_keynote.png" alt="Jensen Huang Keynote at GTC 2025" style="max-height: 350px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">Jensen Huang on stage during the keynote.</figcaption>
</figure>

A few things stuck with me:

**The trillion-dollar compute thesis.** The argument is straightforward: reasoning AI and agentic systems require fundamentally more compute than what we've been building for. Datacenter investment is shifting accordingly. Whether you buy the specific numbers or not, the directional bet is clear.

**One-year release cycles.** NVIDIA is now committing to annual infrastructure updates—new GPUs, CPUs, and accelerated computing features every year. The upcoming Vera Rubin architecture is next in line, focused on datacenter efficiency. For those of us building on this stack, it means the ground is constantly shifting.

**Photonics and storage.** Less flashy, but arguably more important for scale: advanced networking and AI-optimized storage are becoming first-class concerns. Power consumption and data movement are real bottlenecks at scale, and NVIDIA is addressing them directly.

**Physical AI.** The Isaac and Cosmos platforms represent NVIDIA's push into robotics and industrial automation. Jensen framed this as a $50 trillion opportunity. Even if you discount the figure, the underlying point stands: AI is moving from screens into the physical world.

For anyone building AI products, the message was clear—the infrastructure layer is evolving faster than most application layers can keep up with.

## Sessions Worth Mentioning

I attended more sessions than I can properly summarize, but a few stood out:

**Agentic AI architectures.** Engineers from several AI labs walked through patterns for building agents that can reason, plan, and execute multi-step tasks. The discussion got into the weeds on failure modes, retry logic, and how to handle ambiguous instructions. Practical stuff. Much of it directly applicable to what we're building at Hereby.

**Inference optimization.** Sessions on vLLM and TensorRT-LLM were densely technical, covering throughput-latency tradeoffs, batching strategies, and memory management. If you're running inference at any real scale, these details matter. I left with a few concrete ideas for our own stack.

**Document AI and multimodal models.** Given our work on contract processing, these sessions were directly relevant. Vision-language models are improving quickly, and the pipelines for extracting structured data from documents are becoming more reliable. Still not solved, but the trajectory is encouraging.

**Blackwell and the software stack.** The hardware sessions are always interesting, but what struck me more was the emphasis on the software ecosystem around Blackwell. The co-evolution of hardware and software is getting tighter, with energy efficiency now treated as a core metric alongside raw performance.

## The Hallway Track

Conferences like GTC are often more valuable between sessions than during them.

I talked with researchers from a few major AI labs who were surprisingly candid about what's working and what isn't. Met a small team from San Francisco building an AI-powered education product—four people, shipping fast, clearly onto something. Had longer conversations with enterprise engineers dealing with the unglamorous reality of deploying models at scale: versioning, monitoring, explaining failures to stakeholders.

What came up repeatedly wasn't the theoretical challenges you read about in papers. It was the practical stuff: handling edge cases that break your demos, building user trust when your system is probabilistic, managing costs when inference bills start to surprise you. The gap between research and production is narrower than it used to be, but it's still real.

## Talking About Hereby

One of my goals for the trip was to get outside perspective on **Hereby** (also known as Donue AI), the AI-powered contract management platform we're building. It's early-stage, built on OCR, LLMs, and agentic workflows. Exactly the kind of thing that's easy to pitch and hard to ship well.

Describing it to engineers and founders at GTC was useful. A few observations:

The problem resonates. Contract management is tedious everywhere, and people immediately understood why AI could help. That's validating, but it's also table stakes—the challenge is in the execution.

Conversations surfaced ideas I hadn't considered. Different industries have different pain points around contracts, and some use cases I'd mentally deprioritized turned out to be more interesting than I'd assumed.

The skepticism was productive. People who've shipped AI products know the gap between a good demo and a reliable system. Honest questions about edge cases, trust, and cost helped calibrate our roadmap.

Showing early work to an audience this technical is humbling. The bar is high. But it also confirmed that the problem is worth solving.

## The Certification

While I was there, I took the **NVIDIA-Certified Associate: Generative AI LLMs** exam. Partly as a personal benchmark, partly because preparing for it forced me to consolidate knowledge I'd accumulated piecemeal.

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_nvidia_certificate.png" alt="NVIDIA Generative AI LLMs Certification" style="max-height: 350px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">NVIDIA-Certified Associate: Generative AI LLMs.</figcaption>
</figure>

The exam covers transformer fundamentals, training methods (pre-training, fine-tuning, RLHF), inference optimization, responsible AI, and practical deployment. Nothing you wouldn't encounter building real systems, but having it formalized helped fill gaps I didn't know I had.

I passed. More importantly, the prep work was worth doing regardless of the outcome.

## What I Took Away

A few observations that have stuck with me since returning:

**The pace is real.** What was impressive last year is now expected. This isn't hype—it's visible in the demos, the conversations, and the roadmaps. Staying current requires active effort.

**Infrastructure matters more now.** As base models become more accessible, the ability to deploy them efficiently becomes the differentiator. Inference costs, latency, and reliability are where competitive advantage lives.

**Agents are the next thing.** The shift from single-turn completions to multi-step agentic workflows isn't just an incremental change. It opens up categories of applications that weren't previously feasible. We're still figuring out the patterns, but the direction is clear.

**Conferences still matter.** For all the remote-first tooling we have, the density of useful conversations at an event like GTC is hard to replicate online. Ideas cross-pollinate faster in person.

**We're early.** Despite the noise, most of the potential here is still untapped. The infrastructure is maturing, the models are improving, but the applications that will define this era are still being figured out.

## What's Next

I came back from San Jose with a longer to-do list than I left with. Some of it is technical—specific optimizations to try, patterns to experiment with. Some of it is strategic—a sharper sense of where Hereby fits in the broader landscape.

Building AI products that actually work for users remains hard. The gap between what's technically possible and what's practically reliable is where most of the work lives. But being around people who are actively closing that gap is useful. It's a reminder that the problems are tractable, even when they're difficult.

To everyone I talked to at GTC: thanks for the conversations. If you're building in this space and want to compare notes, feel free to reach out.

---

*I'm always interested in talking with people working on AI products. Links are below.*
