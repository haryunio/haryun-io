---
layout: post
title: "NVIDIA GTC 2025: AI 최전선에서의 영감"
categories: [articles]
tags: [Article, AI, Conference, NVIDIA, LLM]
featured_image_thumbnail: /images/GTC2025/GTC2025_main_pic.jpg
featured_image: /images/GTC2025/GTC2025_main_pic.jpg
featured: true
hidden: false
lang: ko
page_id: nvidia-gtc-2025
---

2025년 3월, 산호세에서 열린 NVIDIA GTC 2025에 참석했습니다. 막연한 관심과 호기심을 가지고 배우기 위해서 갔다가, 업계가 실제로 어디로 향하고 있는지에 대한 깊은 인사이트를 얻고 돌아온 행사였습니다.

<!--more-->

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_main_pic.jpg" alt="NVIDIA GTC 2025 메인 행사장" style="max-height: 400px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">산호세 컨벤션 센터의 메인 행사장.</figcaption>
</figure>

## 첫인상

GTC에는 특유의 에너지가 있습니다. 논문이나 GitHub으로만 보던 엔지니어, 연구자, 창업자들이 커피 줄에서 바로 옆에 서 있고, 대화는 빠르게 오가지만 깊이가 있습니다.

올해는 생성형 AI, 자율 시스템, 로보틱스, 양자 컴퓨팅을 다루는 900개 이상의 세션이 열렸습니다. 모든 세션을 따라가기는 어려웠지만, 놓친 세션들조차도 참석자들과의 복도 대화를 통해 중요한 맥락을 얻는 계기가 됐습니다.

## 젠슨 황의 기조연설

기조연설은 언제나 그렇듯 컨퍼런스에서 가장 중요한 이벤트입니다. 젠슨 황은 기술 로드맵을 마치 필연처럼 들리게 만드는 방식이 있습니다. 예측을 듣는다기보다, 이미 진행 중인 흐름을 확인하는 느낌에 가깝습니다.

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_jensen_hwang_keynote.png" alt="GTC 2025 젠슨 황 기조연설" style="max-height: 350px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">기조연설 중 무대 위의 젠슨 황.</figcaption>
</figure>

몇 가지가 기억에 남았습니다:

**1조 달러 규모의 컴퓨팅 기회.** 요지는 단순합니다. 추론형 AI와 에이전트 시스템은 지금까지의 워크로드보다 근본적으로 더 많은 컴퓨팅을 필요로 하고, 데이터센터 투자는 그 방향으로 재편되고 있습니다. 숫자를 그대로 받아들이지 않더라도, 방향성은 분명했습니다.

**1년 주기의 릴리스.** NVIDIA는 매년 GPU, CPU, 가속 컴퓨팅 기능을 포함한 인프라 업데이트를 약속하고 있습니다. 다음은 Vera Rubin 아키텍처로, 데이터센터 효율성에 초점을 둔다고 했습니다. 이 스택 위에서 제품을 만드는 입장에서는, 기반이 계속 바뀐다는 뜻이기도 합니다.

**광통신과 스토리지.** 덜 화려하지만, 확장성 측면에서는 오히려 더 중요한 지점입니다. 고급 네트워킹과 AI 최적화 스토리지가 이제는 부차적인 요소가 아니라 핵심 관심사가 됐습니다. 규모가 커질수록 전력과 데이터 이동이 실제 병목이 되기 때문이고, NVIDIA는 이를 정면으로 다루고 있었습니다.

**물리적 AI.** Isaac과 Cosmos 플랫폼은 로보틱스와 산업 자동화로의 확장을 보여 주는 신호였습니다. 젠슨은 이를 거대한 시장 기회로 설명했는데, 규모에 대한 해석을 떠나 핵심 메시지는 명확했습니다. AI가 화면 속을 넘어 물리 세계로 이동하고 있다는 점입니다.

AI 제품을 만드는 입장에서는, 인프라 계층이 애플리케이션 계층이 따라잡기 어려울 정도로 빠르게 진화하고 있다는 점이 특히 인상적이었습니다.

## 언급할 만한 세션들

제대로 요약하기 어려울 정도로 많은 세션에 참석했지만, 몇 가지가 눈에 띄었습니다:

**에이전트형 AI 아키텍처.** 여러 AI 연구소의 엔지니어들이 추론, 계획, 다단계 실행이 가능한 에이전트를 설계하는 패턴을 공유했습니다. 실패 모드, 재시도 로직, 모호한 지시 처리 같은 구현 디테일까지 깊게 들어갔고, 상당히 실용적이었습니다. Hereby에서 하는 일에도 직접 연결되는 내용이 많았습니다.

**추론 최적화.** vLLM과 TensorRT-LLM 세션은 기술 밀도가 높았습니다. 처리량과 지연의 트레이드오프, 배칭 전략, 메모리 관리 등, 실제로 규모 있게 추론을 운영할 때 중요한 주제들이었습니다. 우리 스택에 적용해 볼 만한 구체적인 아이디어도 몇 가지 얻었습니다.

**문서 AI와 멀티모달 모델.** 계약 처리를 다루는 입장에서는 특히 직접적이었습니다. 비전-언어 모델의 품질이 빠르게 개선되고 있고, 문서에서 구조화 데이터를 추출하는 파이프라인도 점점 더 신뢰할 수 있는 방향으로 발전하고 있었습니다. 완전히 해결된 문제는 아니지만, 방향은 고무적이었습니다.

**Blackwell과 소프트웨어 스택.** 하드웨어도 흥미로웠지만, 더 인상적이었던 것은 Blackwell을 둘러싼 소프트웨어 생태계에 대한 강조였습니다. 하드웨어와 소프트웨어의 공진화가 더 촘촘해지고 있고, 에너지 효율성도 이제는 순수 성능과 함께 핵심 지표로 다뤄지고 있었습니다.

## 복도 트랙

GTC와 같은 컨퍼런스는 종종 세션 중보다 세션 사이에 더 가치가 있습니다.

몇몇 주요 AI 연구소의 연구원들과 대화를 나눴는데, 무엇이 효과가 있고 무엇이 그렇지 않은지에 대해 놀라울 정도로 솔직했습니다. 이후에는 샌프란시스코에서 AI 기반 교육 제품을 만드는 작은 팀도 만났습니다. 제품 개발 속도와 시장 진입 전략은 전통적인 조직과 확연히 달랐습니다. 또 모델을 실제 규모로 배포하는 현실을 다루는 엔터프라이즈 엔지니어들과는 더 긴 대화를 나눴습니다. 버전 관리, 모니터링, 이해관계자에게 실패를 설명하는 문제는 결국 현장에서 반복해서 마주치는 주제였습니다.

반복해서 나온 이야기는 논문에서 읽는 이론적 난제라기보다, 현장에서 문제를 만드는 실무적 디테일이었습니다. 데모를 무너뜨리는 예외 케이스, 확률적 시스템에서 사용자 신뢰를 쌓는 방법, 예상보다 빠르게 불어나는 추론 비용을 관리하는 일 같은 것들입니다. 연구와 프로덕션의 간극은 예전보다 좁아졌지만, 여전히 현실로 존재합니다.

## Hereby에 대해 이야기하기

이번 여행의 목표 중 하나는 우리가 만들고 있는 AI 기반 계약 관리 플랫폼 **Hereby**(당시에는 Donue AI라는 이름으로 소개하기도 했습니다)에 대해 외부 관점을 얻는 것이었습니다. OCR, LLM, 에이전트 워크플로우를 기반으로 하는 초기 단계 제품이고, 설명은 쉽지만 제대로 운영 가능한 형태로 만드는 것이 어려운 종류의 문제입니다.

GTC의 엔지니어와 창업자들에게 설명하는 것은 유용했습니다. 몇 가지 관찰:

**문제 정의는 공감대를 얻습니다.** 계약 관리는 어디서나 번거롭고, AI가 왜 도움이 될 수 있는지 대부분 즉시 이해했습니다. 다만 이것은 출발선에 가깝고, 난이도는 결국 실행력에 있습니다.

**대화는 새로운 사용 사례를 드러냅니다.** 산업마다 계약과 관련된 고통 지점이 다르고, 우선순위를 낮춰 두었던 일부 시나리오가 예상보다 더 매력적으로 보이기도 했습니다.

**회의론이 오히려 도움이 됩니다.** AI 제품을 출시해 본 사람들은 좋은 데모와 신뢰할 수 있는 시스템의 차이를 잘 알고 있습니다. 예외 케이스, 신뢰, 비용에 대한 직설적인 질문이 로드맵을 더 현실적으로 조정하는 데 도움이 됐습니다.

이 정도로 기술적인 청중에게 초기 제품을 보여 주는 경험은 겸손해지게 만듭니다. 기준이 높기 때문입니다. 동시에, 이 문제가 해결할 가치가 있다는 확신도 다시 확인할 수 있었습니다.

## 자격증

현장에 있는 동안 **NVIDIA-Certified Associate: Generative AI LLMs** 시험도 응시했습니다. 개인적인 기준점이 필요했던 것도 있지만, 무엇보다 조각조각 쌓아 온 지식을 한 번 정리하게 만드는 계기가 될 것 같았습니다.

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_nvidia_certificate.png" alt="NVIDIA 생성형 AI LLMs 자격증" style="max-height: 350px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">NVIDIA-Certified Associate: Generative AI LLMs.</figcaption>
</figure>

시험 범위는 트랜스포머 기초, 학습 방법(사전학습, 파인튜닝, RLHF), 추론 최적화, 책임 있는 AI, 실무 배포까지 폭넓었습니다. 실제 시스템을 만들며 마주치는 주제들이지만, 공식적으로 정리된 형태로 훑어보니 제가 놓치고 있던 빈틈을 메우는 데 도움이 됐습니다.

합격했습니다. 무엇보다 준비 과정 자체가 결과와 무관하게 충분히 의미 있었습니다.

## 얻어간 것

돌아온 이후로 기억에 남는 몇 가지 관찰:

**속도는 과장이 아닙니다.** 작년에 인상적이었던 것들이 이제는 기본 기대치가 됐습니다. 데모, 대화, 로드맵 어디에서나 확인할 수 있었고, 최신 흐름을 따라가려면 의식적인 노력이 필요합니다.

**인프라는 더 중요해졌습니다.** 기본 모델 접근성이 높아질수록, 효율적으로 배포하고 운영하는 능력이 차별화 요인이 됩니다. 추론 비용, 지연, 신뢰성이 결국 경쟁력이 됩니다.

**에이전트가 다음 흐름입니다.** 단일 턴 응답에서 다단계 에이전트 워크플로우로의 전환은 단순한 점진 변화가 아닙니다. 이전에는 현실성이 낮았던 응용의 범위를 열어 줍니다. 패턴은 아직 정교화되는 중이지만, 방향은 명확합니다.

**컨퍼런스는 여전히 중요합니다.** 원격 협업 도구가 충분히 발달했더라도, GTC 같은 이벤트에서의 대화 밀도는 온라인으로 대체하기 어렵습니다. 대면 환경에서는 아이디어가 더 빠르게 오가고, 연결이 더 쉽게 생깁니다.

**우리는 아직 초기에 있습니다.** 소란스러운 분위기와 별개로, 잠재력의 대부분은 아직 현실화되지 않았습니다. 인프라는 성숙해지고 모델은 개선되고 있지만, 이 시대를 규정할 응용은 아직 만들어지는 중입니다.

## 다음은?

산호세에 갈 때보다 더 긴 할 일 목록을 들고 한국에 돌아왔습니다. 기술적으로는 시도해 보고 싶은 최적화와 실험 패턴이 생겼고, 전략적으로는 Hereby가 더 큰 그림에서 어디에 놓여야 하는지에 대한 감각이 또렷해졌습니다.

사용자에게 실제로 작동하는 AI 제품을 만드는 일은 여전히 어렵습니다. 기술적으로 가능하다는 것과, 운영 관점에서 신뢰할 수 있다는 것 사이의 간극이 가장 큰 작업량이 몰리는 지점입니다. 다만 그 간극을 실제로 줄이고 있는 사람들 곁에 있는 것만으로도 얻는 것이 많습니다. 문제가 어렵더라도 충분히 다룰 수 있다는 감각을 다시 갖게 해 줍니다.

GTC에서 이야기 나눈 모든 분들께 감사드립니다. 이 분야에서 무언가를 만들고 있고 메모를 나누고 싶다면, 언제든지 연락 주세요.

---

*AI 제품을 만드는 사람들과 이야기하는 것에 항상 관심이 있습니다. 링크는 아래에 있습니다.*
