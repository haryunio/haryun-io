---
layout: post
title: "NVIDIA GTC 2025: AI 최전선에서의 영감"
categories: [articles]
tags: [Article, AI, Conference, NVIDIA, LLM]
featured_image_thumbnail: /images/GTC2025/GTC2025_main_pic.jpg
featured_image: /images/GTC2025/GTC2025_main_pic.jpg
featured: true
hidden: false
lang: ko
page_id: nvidia-gtc-2025
---

2025년 3월, 산호세에서 열린 **NVIDIA GTC 2025**에 다녀왔습니다. 처음엔 그냥 "한번 가보자"는 마음으로 출발했는데, 돌아올 때는 업계가 실제로 어디로 가고 있는지에 대한 인사이트를 얻어 왔습니다.

<!--more-->

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_main_pic.jpg" alt="NVIDIA GTC 2025 메인 행사장" style="max-height: 400px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">산호세 컨벤션 센터 메인 행사장.</figcaption>
</figure>

## 첫인상

GTC는 분위기 자체가 조금 다릅니다. 논문이나 GitHub에서만 보던 엔지니어, 연구자, 창업자들이 커피 줄 옆에 그냥 서 있고요. 대화는 짧고 빠르게 오가는데, 이상하게 내용은 꽤 깊게 들어갑니다.

올해는 생성형 AI, 자율 시스템, 로보틱스, 양자 컴퓨팅 등으로 **900개가 넘는 세션**이 열렸습니다. 솔직히 전부 따라가긴 불가능했지만, 못 들은 세션도 크게 아쉽진 않았습니다. 복도에서 누가 들은 얘기를 요약해 주면 그걸로 또 질문이 뻗고, 자연스럽게 토론이 생기더라고요.

## 젠슨 황의 기조연설

기조연설은 역시 컨퍼런스의 중심입니다. 젠슨 황은 기술 로드맵을 얘기하는데, “전망”을 듣는 느낌이라기보다 이미 진행 중인 흐름을 확인하는 느낌에 더 가깝습니다.

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_jensen_hwang_keynote.png" alt="GTC 2025 젠슨 황 기조연설" style="max-height: 350px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">기조연설 중 무대 위의 젠슨 황.</figcaption>
</figure>

특히 기억에 남았던 포인트들은 다음과 같습니다.

**1조 달러 규모의 컴퓨팅 기회.**  
핵심은 단순합니다. 추론형 AI, 에이전트 시스템이 본격화될수록 지금까지의 워크로드랑은 비교가 안 될 정도로 컴퓨팅 파워가 더 필요하다는 얘기였고, 데이터센터 투자도 그 방향으로 재편되고 있다는 메시지였습니다. 숫자를 그대로 받아들이지 않더라도, 방향 자체는 꽤 명확했습니다.

**1년 주기의 릴리스.**  
NVIDIA는 GPU, CPU, 가속 컴퓨팅 기능을 포함한 인프라 업데이트를 **매년** 하겠다고 못 박았습니다. 다음 아키텍처로는 Vera Rubin을 언급했고, 데이터센터 효율을 더 강하게 밀어붙인다고 했습니다. 이 위에서 제품을 만드는 입장에서는, 기반이 계속 움직인다는 뜻이기도 합니다.

**광통신과 스토리지.**  
덜 화려한 주제처럼 보이지만, 스케일이 커질수록 결국 여기서 병목이 나기 쉽습니다. 전력과 데이터 이동이 진짜 문제로 튀어나오는 순간이 오니까요. 고급 네트워킹과 AI 최적화 스토리지가 이제는 “부가 요소”가 아니라 핵심으로 올라왔다는 점이 인상적이었습니다.

**물리적 AI(Physical AI).**  
Isaac과 Cosmos 플랫폼 이야기는 로보틱스/산업 자동화로의 확장을 보여주는 신호처럼 보였습니다. 젠슨은 이를 거대한 시장 기회로 설명했는데, 규모를 어떻게 해석하든 메시지는 분명했습니다. AI가 화면 안에서만 끝나는 게 아니라, 물리 세계로 넘어가고 있다는 겁니다.

AI 제품을 만드는 입장에서 가장 크게 남은 건 이거였습니다.  
**인프라 레이어가 애플리케이션 레이어가 따라가기 힘들 정도로 빨리 진화하고 있다**는 것.

## 언급할 만한 세션들

세션이 너무 많아서 다 정리하긴 어렵지만, 특히 기억에 남는 것들은 아래였습니다.

**에이전트형 AI 아키텍처.**  
여러 AI 연구소 엔지니어들이 추론, 계획, 다단계 실행이 가능한 에이전트를 설계하는 패턴을 공유했습니다. 실패 모드, 재시도 로직, 모호한 지시 처리 같은 구현 디테일까지 꽤 깊게 들어갔고요. 데모용 이야기보다 운영에 가까운 얘기가 많아서 좋았습니다. Hereby에서 하는 일과도 직접 연결되는 부분이 많았습니다.

**추론 최적화.**  
vLLM, TensorRT-LLM 세션은 진짜 기술 밀도가 높았습니다. 처리량과 지연의 트레이드오프, 배칭 전략, 메모리 관리 등… 규모 있게 추론을 운영할 때 결국 비용으로 돌아오는 주제들이었습니다. “이건 우리 스택에 바로 적용해볼 수 있겠다” 싶은 아이디어도 몇 개 챙겼습니다.

**문서 AI와 멀티모달 모델.**  
계약 처리를 다루는 입장이라 특히 관심이 갔습니다. 비전-언어 모델 품질이 확실히 빠르게 좋아지고 있고, 문서에서 구조화 데이터를 뽑아내는 파이프라인도 점점 더 신뢰할 만해지는 흐름이 보였습니다. 아직 완전히 끝난 문제는 아니지만, 방향은 꽤 고무적이었습니다.

**Blackwell과 소프트웨어 스택.**  
하드웨어 자체도 흥미롭지만, 이번엔 오히려 Blackwell을 둘러싼 소프트웨어 생태계를 더 강조하는 느낌이었습니다. 하드웨어/소프트웨어 공진화가 더 촘촘해지고 있고, 에너지 효율도 이제는 순수 성능만큼이나 핵심 지표로 다뤄지고 있었습니다.

## 복도 트랙

GTC 같은 컨퍼런스는 세션 중보다 세션 사이에서 더 많이 얻을 때가 많습니다.

몇몇 주요 AI 연구소 연구원들과는 “지금 뭐가 되고, 뭐가 안 되는지”를 생각보다 솔직하게 얘기할 수 있었습니다. 샌프란시스코에서 AI 기반 교육 제품을 만드는 소규모 팀도 만났는데, 개발 속도나 시장 진입 전략이 전통적인 조직이랑 확실히 달랐습니다. 또 엔터프라이즈 환경에서 모델을 실제 규모로 배포하는 엔지니어들과는 더 오래 이야기했는데, 버전 관리, 모니터링, 실패를 이해관계자에게 설명하는 문제 같은 게 결국 계속 반복되는 주제라는 걸 다시 느꼈습니다.

공통적으로 나왔던 이야기는 논문에서 보는 “이론적 난제”보다는, 현장에서 데모를 무너뜨리는 실전 디테일이었습니다. 예외 케이스, 확률적 시스템에서 신뢰를 쌓는 방법, 생각보다 빨리 불어나는 추론 비용을 어떻게 잡는지 같은 것들이요. 연구와 프로덕션의 간극은 확실히 줄어들었지만, 여전히 현실로 존재합니다.

## Hereby에 대해 이야기하기

이번 여행의 목표 중 하나는 우리가 만들고 있는 AI 기반 계약 관리 플랫폼 **Hereby**(당시에는 Donue AI라는 이름으로 소개하기도 했습니다)에 대해 외부 관점을 얻는 것이었습니다. OCR, LLM, 에이전트 워크플로우 기반의 초기 단계 제품인데, 설명은 쉽지만 “운영 가능한 형태”로 만드는 건 정말 어려운 종류의 문제입니다.

그래서 GTC에서 엔지니어, 창업자들에게 Hereby를 설명하고 피드백을 받는 시간이 꽤 유용했습니다. 정리하면 아래 세 가지입니다.

**문제 정의는 공감대를 얻습니다.**  
계약 관리는 어디서나 번거롭고 비효율적이라, “AI가 여기서 도움이 되겠다”는 반응은 대부분 바로 나왔습니다. 다만 이건 시작점이고, 난이도는 결국 실행에서 갈립니다.

**대화가 새로운 사용 사례를 드러냅니다.**  
산업마다 계약의 고통 지점이 다르고, 제가 우선순위를 낮춰놨던 시나리오가 오히려 더 매력적으로 보이기도 했습니다.

**회의론이 오히려 도움이 됩니다.**  
AI 제품을 실제로 출시해 본 사람들은 좋은 데모와 신뢰할 수 있는 시스템의 차이를 너무 잘 압니다. 예외 케이스, 신뢰, 비용에 대한 직설적인 질문이 로드맵을 현실적으로 조정하는 데 도움이 됐습니다.

기술적으로 탄탄한 청중에게 초기 제품을 보여주는 경험은 꽤 겸손해지게 만듭니다. 기준이 높으니까요. 그럼에도 동시에, 이 문제는 충분히 해결할 가치가 있다는 확신도 다시 확인할 수 있었습니다.

## 자격증

현장에 있는 동안 **NVIDIA-Certified Associate: Generative AI LLMs** 시험도 응시했습니다. 개인적으로 기준점이 하나 필요했던 것도 있고, 무엇보다 흩어져 있던 지식을 한 번 정리해보고 싶었습니다.

<figure style="text-align: center; margin: 2rem 0;">
  <img src="/images/GTC2025/GTC2025_nvidia_certificate.png" alt="NVIDIA 생성형 AI LLMs 자격증" style="max-height: 350px; width: auto; border-radius: 8px;" />
  <figcaption style="margin-top: 0.5rem; font-style: italic; color: #666;">NVIDIA-Certified Associate: Generative AI LLMs.</figcaption>
</figure>

시험 범위는 트랜스포머 기초, 학습 방법(사전학습, 파인튜닝, RLHF), 추론 최적화, 책임 있는 AI, 실무 배포까지 꽤 넓었습니다. 실제 시스템을 만들며 마주치는 주제들이긴 한데, 공식 커리큘럼으로 한 번 쭉 훑으니 제가 비워뒀던 부분이 더 잘 보이더라고요.

결과는 합격이었습니다.  
다만 결과보다, 준비 과정 자체가 충분히 의미 있었습니다.

## 얻어간 것

돌아온 뒤에도 계속 머리에 남는 관찰이 몇 가지 있습니다.

**속도는 과장이 아닙니다.**  
작년에 인상적이던 것들이 올해는 기본 기대치가 돼 있었습니다. 데모, 대화, 로드맵 어디서든 확인할 수 있었고, 최신을 따라가려면 이제는 의식적으로 시간을 써야 합니다.

**인프라의 비중이 더 커졌습니다.**  
기본 모델 접근성이 높아질수록, “효율적으로 배포하고 운영하는 능력”이 차별점이 됩니다. 결국 추론 비용, 지연, 신뢰성이 경쟁력입니다.

**에이전트가 다음 흐름입니다.**  
단일 턴 응답에서 다단계 에이전트 워크플로우로 넘어가는 건 단순한 기능 추가가 아니라, 이전에는 현실성이 낮았던 응용 범주를 열어주는 변화로 보였습니다. 패턴은 아직 정교화되는 중이지만 방향은 꽤 명확합니다.

**컨퍼런스는 여전히 유효합니다.**  
원격 협업 도구가 아무리 좋아져도, GTC 같은 이벤트에서 얻는 대화의 밀도는 온라인으로 대체하기 어렵습니다. 대면 환경에서는 아이디어가 더 빨리 오갑니다.

**우리는 아직 초반입니다.**  
분위기는 시끄럽지만(좋든 나쁘든), 잠재력의 대부분은 아직 현실화되지 않았습니다. 인프라는 성숙해지고 모델은 계속 좋아지지만, 이 시대를 규정할 애플리케이션은 아직 만들어지는 중입니다.

## 다음은?

산호세에 갈 때보다 더 긴 할 일 목록을 들고 한국에 돌아왔습니다. 기술적으로는 바로 실험해 보고 싶은 최적화 포인트가 생겼고, 전략적으로는 Hereby가 더 큰 그림에서 어디에 놓여야 하는지도 좀 더 선명해졌습니다.

사용자에게 "실제로 잘 돌아가는" AI 제품을 만드는 일은 여전히 어렵습니다. 기술적으로 가능하다는 것과, 운영 관점에서 신뢰할 수 있다는 것 사이의 간극이 가장 큰 작업량이 몰리는 지점이니까요. 그래도 그 간극을 실제로 줄여나가는 사람들 옆에 있었던 것만으로도 얻는 게 많았습니다. 문제는 어렵지만, 충분히 해볼 만하다는 감각을 다시 얻게 해줬습니다.

GTC에서 이야기 나눈 모든 분들께 감사드립니다. 이 분야에서 무언가를 만들고 있고 메모를 나누고 싶다면, 언제든지 연락 주세요.

---

*AI 제품을 만드는 사람들과 이야기하는 것에 항상 관심이 있습니다. 링크는 아래에 있습니다.*